# configs/logstash/custom-filters.conf
# This pipeline parses and enriches Zeek and Suricata (EVE) logs.

filter {

  # --- Suricata EVE JSON Logs ---
  # Suricata logs are already in JSON, but we need to parse and add metadata.
  if [log][file][path] =~ "/var/log/nsm/suricata" or "suricata" in [tags] {
    # Parse the raw JSON message
    json {
      source => "message"
      target => "suricata" # Store the parsed data in a 'suricata' field
    }

    # Extract the timestamp from the Suricata event
    date {
      match => [ "[suricata][timestamp]", "ISO8601" ]
      target => "@timestamp" # This sets the event's timestamp correctly in ES
    }

    # Classify the event type for easier Kibana filtering
    if [suricata][event_type] {
      mutate {
        add_field => { "event_type" => "%{[suricata][event_type]}" }
        add_field => { "event_module" => "suricata" }
      }
    }

    # If it's an alert, add critical fields and set severity
    if [suricata][event_type] == "alert" {
      mutate {
        # Copy the signature to a top-level field for easy searching
        add_field => {
          "alert.signature" => "%{[suricata][alert][signature]}"
          "alert.severity" => "%{[suricata][alert][severity]}"
          "alert.category" => "%{[suricata][alert][category]}"
        }
        # Tag all alerts for easy finding
        add_tag => [ "alert", "suricata_alert" ]
      }

      # Convert severity to a keyword and integer for better filtering
      if [suricata][alert][severity] {
        translate {
          field => "[suricata][alert][severity]"
          destination => "alert.severity_label"
          dictionary => {
            "1" => "Low"
            "2" => "Medium"
            "3" => "High"
          }
          fallback => "Unknown"
        }
      }
    }

    # Clean up - remove the original message if parsing was successful
    if "_jsonparsefailure" not in [tags] {
      mutate {
        remove_field => [ "message" ]
      }
    }
  }

  # --- Zeek TSV Logs ---
  # Zeek logs are tab-separated values with a header line.
  # We use the Zeek beat or a custom input to add a 'path' tag.
  if [log][file][path] =~ "/var/log/nsm/zeek" or "zeek" in [tags] {
    # Get the log type from the filename (e.g., 'conn', 'http', 'dns')
    grok {
      match => { "[log][file][path]" => "/var/log/nsm/zeek/%{WORD:zeek_log_type}\.log" }
      add_tag => [ "zeek", "%{zeek_log_type}" ]
    }

    # Use the appropriate Grok pattern based on the log type
    if [zeek_log_type] {
      grok {
        patterns_dir => ["/usr/share/logstash/patterns/zeek"] # Optional: for custom patterns
        match => { "message" => "%{GREEDYDATA:zeek_field_data}" }
        break_on_match => false
      }

      # Split the tab-separated field data into an array
      mutate {
        split => { "zeek_field_data" => "	" } # This is a TAB character
      }

      # Use the ruby filter for complex field mapping based on Zeek log type.
      # This is more reliable than maintaining huge Grok patterns.
      ruby {
        path => "/usr/share/logstash/scripts/zeek_field_mapper.rb" # We'll create this script
      }

      # Add a timestamp for Zeek logs (they have a 'ts' field)
      if [ts] {
        # Convert Zeek's epoch time to a Logstash timestamp
        date {
          match => [ "ts", "UNIX" ]
          target => "@timestamp"
        }
        mutate {
          remove_field => [ "ts" ] # Remove the duplicate timestamp field
        }
      }

      # Set the event module
      mutate {
        add_field => { "event_module" => "zeek" }
        add_field => { "event_type" => "%{zeek_log_type}" }
      }
    }

    # Clean up temporary fields
    mutate {
      remove_field => [ "zeek_log_type", "zeek_field_data" ]
    }
  }

  # --- General Enrichment (Applied to ALL events) ---

  # Add GeoIP information for any source IP
  if [src_ip] {
    geoip {
      source => "src_ip"
      target => "src_geoip"
      fields => ["city_name", "country_name", "country_code2", "location", "ip", "region_name"]
    }
  }

  # Add GeoIP information for any destination IP
  if [dest_ip] {
    geoip {
      source => "dest_ip"
      target => "dest_geoip"
      fields => ["city_name", "country_name", "country_code2", "location", "ip", "region_name"]
    }
  }

  # Add information about the event's source and environment
  mutate {
    add_field => {
      "[@metadata][pipeline]" => "threat-hunt-kit"
      "environment" => "lab"
    }
  }

  # --- Error Handling ---
  # If JSON parsing failed earlier, tag it and try to extract basic info
  if "_jsonparsefailure" in [tags] {
    grok {
      match => { "message" => "^%{TIMESTAMP_ISO8601:timestamp} %{WORD:program}\[%{NUMBER:pid}\]: %{GREEDYDATA:raw_message}" }
      remove_tag => [ "_jsonparsefailure" ]
      add_tag => [ "parse_failure" ]
    }
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }
}